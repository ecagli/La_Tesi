\chapter{Introduction to Side-Channel Attacks} % Main chapter title

\label{ChapterIntroductionSCA}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Introduction to Side-Channel Attacks}

Side-Channel Attacks (SCA) belong to cryptanalysis domain,  since they aim to breach cryptographic security systems. Usually their goal is to retrieve a secret variable of a cryptographic algorithm, typically a secret key. They distinguish from classic mathematical cryptanalysis techniques for the fact that they are based on information gained from the physical implementation of a cryptosystem, rather than theoretical weaknesses in the algorithms.  

\subsubsection{Divide-and-Conquer}
Side-Channel Attacks go beyond the cryptographic complexity coming from key size, and assuring in classical cryptanalysis a certain security level. Indeed, no matter the size of a cryptographic algorithm inputs, outputs, keys and internal variables, once it is implemented in hardware operations will always be executed over variables of a bounded size. Such a bound depends on the hardware architecture. For example, in an 8-bit architecture an RSA with 1024-bit-sized key, modulo and plaintext will be somehow implemented as multiple operations over 8-bit blocks of observable data. This fact allows an attacker to apply the \emph{divide-and-conquer} strategy: if his goal is to retrieve the full 128-bit AES key or 1024-bit RSA key, he will smartly divide his problem in retrieving small parts of such keys at time, called \emph{subkeys}. 

\begin{remark}
The core of an RSA implementation is the computation of a modular exponentiation with base, modulo and exponent being some big numbers (\eg 1024 bits). A myriad of different algorithms have been proposed to implement in hardware the RSA, which differ from each other for many factors: the way of representing data (\eg Montgomery representation, binary representations with signed bits, Chinese Reminder Theorem representation \dots), the way of scanning the exponent (\eg scan the exponent bit by bit, or window by window, from right to left or left to right, priorly decomposing the exponent or not, \dots), the way of performing in hardware the multiplication (\eg schoolbook, Montgomery, Barrett, \dots). Each choice impacts the size of the needed hardware and the time of the computation. A quite exhaustive state-of-the-art of such implementations is provided in \cite{koc1994high}. 
% aggiungi citazione di Sliding Right into Disaster: Left-to-Right Sliding Windows Leak per dire che ancora oggi la questione della resistenza delle implementazioni agli SCA Ã¨ soggetto di ricerche
\end{remark}

\subsubsection{Sensitive Variable}
In order to make inference on such subkeys, an attacker acquires side-channels signals, \eg instantaneous power consumption or electromagnetic irradiation, during the execution of the algorithm. Such signals are collected into vectors called \emph{traces} (or \emph{acquisitions}). Such traces will be denoted as observations $\vLeakVec_i$ of a random real vector $\vaLeakVec$, where each coordinate corresponds to a time sample of the acquired signal. The goal of the side-channel analysis is finding the right association between a trace (or a set of traces) and the value assumed by a target \emph{sensitive variable} $\sensRandVar$ during its/their acquisition. A sensitive variable is a quantity handled during the algorithm that tells something about a secret of the implementation. Actually, it would be better to call it \emph{sensitive target}, since it might not be variable. Some typical examples of sensitive variables include: 



\begin{itemize}
\item $\sensRandVar = \keyRandVar$ with $\keyRandVar$ a secret subkey - this is the most direct choice for a sensitive target, nevertheless it is often not variable, since in some cases a device exploits always the same key for a given embedded primitive. When the target is not variable we are performing a \emph{simple attack} (see below);
\item a cryptographic variable that depends over a sufficiently small subkey and a part of a known input variable $\publicParRandVar$: $\sensRandVar = \sensFunction(\keyRandVar,\publicParRandVar)$ - this is the classical choice to perform a so-called \emph{differential} or \emph{advanced} SCA (see below);
\item any function of a cryptographic variable (ex: $\HW(\sensFunction(\keyRandVar,\publicParRandVar))$), where $\HW$ represent the Hamming weight. We will see later in which sense it can be interesting to not target a variable but a non-injective function of a variable as the Hamming weight is;
\item an operation (ex: $\sensRandVar \in \{\mathrm{square}, \mathrm{multiply}\}$)
\item a register (ex: $\sensRandVar$ is the register used to store results of operations in a Montgomery ladder implementation of RSA)
\end{itemize}
In this thesis we will try as much as possible to abstract from the form of the sensitive variable, thinking of any entity $\sensRandVar$ that assumes values in a finite set $\sensVarSet$ and whose value permit an attacker to make inference about a secret of the implemented algorithm.

\subsubsection{Leakage Models}
The underlying hypothesis of a SCA is that some information about internal variables (or parts of internal variables) of the implemented algorithm leak during its execution through some observable \emph{side} channels. Such leakages are collectable in the form of signal traces, observing such channels. Depending on the observed channel (\emph{e.g. power consumption, electromagnetic irradiation, time, \dots}), different properties might influence the form of the leakage, and should be taken into account for the construction of a leakage model.\\
If we allow a Side-Channel attacker to make use of a probing station to directly access the circuit wires and monitor the exact values of some intermediate values, this attacker will observe leakages following the so-called \emph{probing model}. To define this model no further hypothesis are needed, for example no noise is taken into account. As explained in \ref{sec:classification_attacks}, SCAs typically refer to non-invasive attacks, so in Side-Channel literature the probing model has been introduced as a worst-case abstract model, and is mainly considered in order to provide formal security proofs for some kinds of countermeasures. More precisely the $d$-probing model \cite{ishai2003private}, in which an attacker can probe $d$ different wires at a time, provides a good model to exhibit security proofs for $d$-th order masking schemes (cf. \ref{sec:masking}). \\
The most common passive leaking channel considered in literature being the power consumption. For such a physical quantity many efforts have been done to propose adherent leakage models. A detailed modelling for power consumption of CMOS circuits is proposed in the \emph{DPA book} \cite{mangard2008power}. After a description of the physical factors influencing the power consumption (divided into static and dynamic) of single logic cells, the authors propose to assume two different points of view to model and develop simulations of the power consumption: the designer point of view can bring to a quite accurate and detailed model, essentially based over his circuit transistor netlists. On the contrary an attacker would be satisfied by considering some easier modelisation, often based over the \emph{Hamming distance} ($\HD$) or the \emph{Hamming-Weight} ($\HW$) of internal variables. Indeed these two functions well-fit the consumption behaviour of circuits registers and buses, that consume depending on how many bits set to 1 or 0 they store or transport (Hamming weight) or how many of them switch their value for 0 to 1 or vice-versa during computations (Hamming distance). \\
When an attacker has chosen its sensitive target $\sensRandVar$ and deals with concrete acquisitions, he does not need a complete power model, but only  a way to modelise the relative differences between leakages for different values of $\sensRandVar$, in order to distinguish traces related to different values of $\sensRandVar$, or in other terms, closer to the machine learning language, to classify traces depending on their associated value of $\sensRandVar$. A statistical model is then sufficient to him. Thus for an attacker, the wider considered model in Side-Channel community is the one sometimes called \emph{noisy leakage model}. In this model the leakage is a random variable obtained by the sum of a deterministic function of the sensitive variable $\sensRandVar$ and a random noise. In general the noise has a Gaussian distribution of null mean and variance $\sigma^2$:
\begin{equation}
\vaLeak = \leakFunction(\sensRandVar) + \noise \mbox{ ,}
\end{equation}
with $\noise \approx \mathcal{N}(0,\sigma^2)$.


\subsubsection{Vertical vs Horizontal SCAs}
Attacks in which sensitive information
is extracted from a single acquisition split into several parts are called \emph{horizontal}. Horizontal attacks may apply when the same sensitive variables are involved in many internal operations during the overall algorithm (for example as in \cite{battistello2016horizontal}). Algebraic SCAs (see below) are horizontal attacks as well, in which inferences over potentially every cryptographic variable are done, followed by a deep analysis of algebraic relations between such sensitive variables. Collision attacks (see below) may (or not) be executed in a horizontal fashion. Horizontal attacks differ from the so-called \emph{vertical} attacks where information is obtained from different algorithm executions. The nice notion of \emph{Rectangle} attack has been introduced in \cite{bauer2013horizontal} to refer to attacks that both exploit vertical and horizontal leakages.

\subsubsection{Profiling vs Non-Profiling SCAs}
As anticipated in Sec.~\ref{sec:this_thesis_objectives}, when an open sample of the attacked device is available to make a prior characterization of the leaking signals of a device, we talk about \emph{profiling} attacks. When this is not the case, we talk about \emph{non-profiling} attacks. \\
A profiling attack is thus divided into two distinct phases. The first one, called \emph{profiling phase} of \emph{characterization} phase exploits some so-called \emph{profiling traces} to build a model of the leakages. Profiling traces are acquisitions taken under known values for the sensitive variable $\sensRandVar$, so are couples $(\vLeakVec_i, \sensVar_i)_{i=1, \dots , \nbProfilingTraces}$ for which the correct association trace/sensitive variable is known. The second phase of a profiling attack is the proper \emph{attack phase}, during which the attacker observes a new set of acquisitions, unknown secret key, and take advantage of the previous characterization to infer over it. \\
As we will see in Chapter~\ref{ChapterIntroML}, in machine learning domain the analogous of profiling attacks context is known under the name of \emph{supervised machine learning}. In supervised machine learning couples $(\vLeakVec_i, \sensVar_i)_{i=1, \dots , \nbProfilingTraces}$ are available and are called \emph{training examples}. The profiling phase is referred to as \emph{training} of \emph{learning} and the attack phase is assimilable to the so-called \emph{test phase}. If no example is available we talk about \emph{unsupervised machine learning}, that we can consider analogous to the non-profiling SCAs branch. 

\subsubsection{Classes}
Throughout this thesis, and each time a profiling attack scenario is supposed,  we will refer to elements of $\sensVarSet$ as \emph{classes}. We will say that acquired traces associated to a same value $\sensVar\in\sensVarSet$ \emph{belong} to the same class $\sensVar$. Eventually we will use the term \emph{label} to denote the classes, in such a way that each trace is \emph{labelled} by an element of $\sensVarSet$, or associated to a label $\sensVar\in\sensVarSet$. In such a context $\nbTracesPerClass$ will denote the number of profiling traces belonging to the class $sensVar$.

\subsubsection{Simple vs Advanced SCAs}
A simple attack is an attack that only need one trace to be applied, except for profiling acquisitions. Such a one-trace attack can be seen as a classification problem in machine learning language: an attacker guesses the value of the secret key from the observation of a single side-channel trace;  in other words, and setting $\sensRandVar$ equal to the definitive secret the attacker is looking for (\eg the whole secret key) the attack consists in classifying one observation, \ie assigning to the single attack trace the corresponding value of $\sensRandVar$. In 2002 Mangard \etal proposed for example a simple power analysis (SPA) strategy to retrieve the whole AES key observing leakages from a single execution of the AES key expansion \cite{mangard2002simple}. When Algebraic SCAs (see below) appeared in literature in 2009, their aim was to be a strategy to perform simple attacks as well.  Attacks for which many observations are acquired with fixed entry parameters and by consequence in which the observed leakage always corresponds to the same value of $\sensRandVar$ are still considered simple attacks. Generically speaking, the attacker exploits the several acquisitions in mainly two ways: he computes their average before performing the classification or he performs the classification of each acquisition (expecting each gives the same outcome) and then applies a function to the several outcomes (\eg majority vote) to guess the right label. We observe that this approach with several observation allows the attacker to reduce the noise impact, while observing many times the same amount of information.\\
An advanced attack is a more powerful strategy: the attacker acquires several acquisitions making entry parameters vary, and by consequence observing leakages related to different values of $\sensRandVar$. This time the variation of the observed sensitive variable is interpretable as a raising of the amount of caught information. The attacker exploits synergistically the information coming from each acquisition: he evaluates each key hypothesis, taking advantage of the algebraic relation between (known) entries, keys and sensitive variables, to find out the one that would better justify the leakages he observed. Classical Differential Power Attacks (DPA) \cite{brier2004correlation} or Correlation Power Attacks (CPA) \cite{brier2004correlation}, as well as attacks based over Mutual Information Analysis (MIA) \cite{batina2011mutual} are advanced attacks. 


\subsubsection{Template Attack}\label{sec:TA}
Introduced in 2004 by Chari \cite{Chari2003}, the so-called \emph{Template Attack} (TA) is the most well-established strategy to run a profiling SCA. It can be performed in a simple or advanced way. The idea of the TA is based over the construction of a so-called \emph{generative model}: in probability, statistic and machine learning \enquote{ ...approaches that explicitly or implicitly model the distribution of inputs as well as outputs are known as generative models, because by sampling from them it is possible to generate synthetic data points in the input space.} \cite{christopher2006pattern}.
In TA the attacker observes the couples $(\vLeakVec_i, \sensVar_i)_{i=1, \dots , \nbProfilingTraces}$  and exploit them to estimate the class-conditional densities  
\begin{equation}\label{eq:class-conditional}
p_{\vaLeakVec}(\vLeakVec_i \given \sensRandVar = \sensVar)\mbox{ ,}
\end{equation}
eventually the prior densities $p_{\vaLeakVec}(\vLeakVec)$, $p_{\sensRandVar}(\sensVar)$, and finally the a-posteriori density, by means of the Bayes' theorem:
\begin{equation}\label{eq:a-posteriori}
p_{\sensRandVar}(\sensVar \given \vaLeakVec) = \frac{p_{\vaLeakVec}(\vLeakVec_i \given \sensRandVar = \sensVar)p_{\sensRandVar}(\sensVar)} {p_{\vaLeakVec}(\vLeakVec_i)}\mbox{ .}
\end{equation}
In the attack phase the attacker acquires new traces that he only can associate to the public parameter $\publicParRandVar$, obtaining couples  $(\vLeakVec_i, \publicParVar_i)_{i=1, \dots , \nbAttackTraces}$. Then he makes key hypothesis $\keyVar \in \keyVarSet$ and, making the assumption that each acquisition is an independent observation of $\vaLeakVec$, he associates to each hypothesis a score given by the joint a-posteriori probability that follows, exploiting distributions \eqref{eq:class-conditional}, \eqref{eq:a-posteriori}:

\begin{equation}
d_{\keyVar} = \prod_{i=1}^{\nbAttackTraces}\prob[\sensRandVar = \sensFunction(\publicParVar_i,\keyVar) \given \vaLeakVec = \vLeakVec_i] \mbox{ .}
\end{equation}

Finally, his best key candidate $\hat{\keyVar}$ is the one maximizing such a joint probability
\begin{equation}\label{eq:max_classifier}
\hat{\keyVar} = \argmax_{\keyVar} d_{\keyVar} \mbox{ .}
\end{equation}

\begin{remark}Since the marginal probability density $p_{\vaLeakVec}(\vLeakVec_i)$ of \eqref{eq:a-posteriori} does not depend on key hypothesis, it is usually neglected. Moreover, in many cases the $\sensRandVar$ follows a uniform distribution, so its probability mass function $p_{\sensRandVar}(\sensVar)$ appearing in \eqref{eq:a-posteriori}  does not influence the ranking of key hypothesis, then it is often neglected as well. 
\end{remark}

\begin{remark}
In the special case of a simple attack, \ie $\nbAttackTraces = 1$, in which $\sensRandVar = \keyRandVar$, the problem becomes a classical machine learning classification problem (as we will discuss over in Chapter~\ref{ChapterIntroML}: the attacker wants to classify the unique attack trace, \ie assign to it a class label (the key). In such a case, the choice proposed by \eqref{eq:max_classifier} is known as \emph{Bayes (optimal) classifier}.\footnote{The term \emph{optimal} distinguishes it from the so-called \emph{Bayes naive classifier}, which introduces an independence assumption between data vector coordinates. The efficiency of a Bayes naive classifier has been analysed in SCA context in 2017 \cite{picek2017template}.} It is proven to be the optimal choice to reduce de misclassification error \cite{christopher2006pattern}.
\end{remark}

In general this approach theoretically exploits all available information and is optimal under an information-theoretical point of view. The crucial point is the estimation of the class-conditional densities \eqref{eq:class-conditional}: the efficiency of the attack strongly depends on the quality of such estimates. 

\paragraph{The Gaussian Hypothesis} A well-established choice to construct class-conditional densities estimations \ref{eq:class-conditional} is the one applied in TA \cite{Chari2003}: it consists in making a class-conditional multivariate Gaussian distribution assumption
\begin{equation}\label{eq:gaussian_assumption}
\vaLeakVec\given \sensRandVar =\sensVar \approx \mathcal{N}(\mumumu_\sensVar, \Sigma_\sensVar)\mbox{ ,}
\end{equation} 
and exploits the profiling traces to estimate the  parameters $\mumumu_\sensVar$, \ie the mean vector of the Gaussian distributions, and $ \Sigma_\sensVar$, \ie the covariance matrices. \\

\begin{remark}This assumption is the same that is done for classification problems, bringing to the \emph{Quadratic Discriminant Analysis} technique, which we will describe in Chapter~\ref{ChapterIntroML}. 
\end{remark}

Many options and choices influence the implementation of a TA: the suppression or not of the marginal densities in \eqref{eq:a-posteriori}, the use of the unbiased estimator or the maximum likelihood estimator for the covariance matrices, the addition of an \emph{homoscedasticity} assumption (assume that all class-covariance matrices are equal). This last assumption, proposed in 2014 in SCA literature \cite{choudary2014efficient},  allows exploiting all profiling traces to estimate a unique so-called \emph{pooled} covariance matrix, instead of using traces belonging to each class to estimate each covariance matrix. The pooled estimation gains in accuracy. 

\begin{remark}
The homoscedasticity assumption is the same that is done for classification problems, bringing to the \emph{Linear Discriminant Analysis} technique, which we will introduce in Chapter~\ref{ChapterIntroML} and more deeply analyse in Chapter~\ref{ChapterLinear}.  
\end{remark}

Other choices that mainly influences the TA efficiency are those related to the PoI selection, or more generically to the dimensionality reduction issue.

\subsubsection{Points of Interest and Dimensionality Reduction}\label{sec:extractors}
The side channel traces are usually acquired by oscilloscopes with a very high sampling rate, which permits a powerful inspection of the component behaviour, but at the same time produces huge- dimensional data, consisting in thousands, or even millions of points. Nevertheless, often only a relatively small part of these time samples is informative, i.e. statistically depends, independently or jointly, on a sensitive target variable. These informative points are called \emph{Points of Interest} (PoI). The dimensionality reduction of the traces is a fundamental pre-processing phase to get efficient and effective SCAs, not too expensive in terms of memory and time consumption. The problem of performing an opportune dimensionality reduction goes hand in hand with the research of PoIs: a convenient dimensionality reduction should enhance the contribution of such PoIs while reducing or nullifying the one provided by non-interesting points. 
The goal of these researches is to study and develop techniques to characterize PoIs and to apply convenient dimensionality reduction techniques, that allow reducing the size of the acquisitions while keeping the exploitable information held by data high enough to allow an SCA to succeed.
Considering the side channel traces as column vectors ${\bf x}$ in $\mathbb{R}^\traceLength$, the compressing phase might be seen as the application of a function $\extract\colon \mathbb{R}^\traceLength\rightarrow \mathbb{R}^\newTraceLength$, called {\em extractor} throughout this thesis.
\todo{A brief overview of state-of-the art statistics to select PoIs}


\subsubsection{Algebraic Side-Channel Attacks}
Algebraic SCAs (ASCA) were firstly proposed in 2009 \cite{ASCA,renauld2009algebraic}. Their aim was to combine profiling SCA strategies (templates-like) to classical cryptanalysis techniques: in these first papers block ciphers implementations are attacked, and the authors added to plaintext and ciphertext knowledge, classically assumed in algebraic cryptanalysis, the access to the (exact) Hamming weights of  several intermediate computations, obtained by side-channel observation. Once recovered as many partial information as possible, it is expressed in the form of an equation system, then converted to a set of clauses treatable by a SAT solver. In opposition to classic SCAs, ASCA approach does not exploit a divide-and-conquer strategy: the whole secret key is retrieved at once, exploiting algebraic relations between intermediate variables. This means, in the case of block ciphers, that the attacker observes leakages occurring during each round of the algorithm, and not only those related to beginning or lasting rounds, were the cryptographic diffusion is limited. This optimal exploitation of the information, allows the ASCA strategy provide efficient simple attacks, \ie succeeding with a single attack trace.\\
Two main weaknesses of this approach are pointed out. First, it does not tolerate errors, implying that it is weak to noise: a wrong side-channel information may put the right key out of the list of key candidates. This is why seminal ASCA papers proposed to equip the strategy with some techniques of detection of impossibilities and likelihood rating. Second, the use of SAT solvers asks to express relations between cipher variables at a bit level. Since in general block ciphers are byte-oriented this produces very large and complex instances, challenging to construct and hard to debug.\\
Two works appeared in 2014 address these two weaknesses. In \cite{soft} a \emph{Soft Analytical Side Channel Attack} (SASCA) is proposed to make the ASCA strategy more tolerant to noise. The idea of such SASCAs is to replace the equation system representation of retrieved intermediate variables with a code, inspired by the low density parity check codes. This approach is still bit-oriented. Then the code is efficiently decoded by an algorithm known as \emph{Belief Propagation}, whose inputs are not the exact values of the retrieved intermediate variables, but their probability distributions, provided by the profiling phase. The noise tolerance is provided by the utilisation of such probabilities instead of exact values. \\
In \cite{Oren2014} a constraint solver is proposed to replace the bit-oriented SAT solver. Such a new solver is designed for side channel cryptanalysis of byte-oriented ciphers, and works in a probabilistic way, as well as the SASCA approach, tracking the likelihoods of values in the secret key. The likelihoods of observed intermediate variables are provided by a template approach, as well as proposed in \cite{Oren:2013} in 2013 under the name of Template-Algebraic SCA (TASCA). The main tool  of the constrained solver is the \emph{conflation operator} for reconciling multiple probability distributions for the same variable.\\

Since all these algebraic side-channel approach are based over a preliminary profiling phase, they are all largely concerned by the dimensionality reduction issue, which is often not explicitly taken into account in literature about this research axe. 

\subsubsection{SCA Metrics}
\todo{definition of rank, guessing entropy}


%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
\section{Main Side-Channel Countermeasures}\label{sec:countermeasures}
\subsection{Random Delays and Jitter}
\subsection{Shuffling}
\subsection{Masking}\label{sec:masking}



%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------
\section{Higher-Order Attacks}
\subsection{Higher-Order Moments Analysis and Combining Functions}
\subsection{Profiling Higher-Order Attacks}
\subsubsection{Profiling with Masks Knowledge}
\subsubsection{Profiling without Masks Knowledge}

