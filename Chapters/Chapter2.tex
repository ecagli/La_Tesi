\chapter{Introduction to Side-Channel Attacks} % Main chapter title

\label{ChapterIntroductionSCA}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Introduction to Side-Channel Attacks}

Side-Channel Attacks (SCA) belong to cryptanalysis domain,  since they aim to breach cryptographic security systems. Usually their goal is to retrieve a secret variable of a cryptographic algorithm, typically a secret key. They distinguish from classic mathematical cryptanalysis techniques for the fact that they are based on information gained from the physical implementation of a cryptosystem, rather than theoretical weaknesses in the algorithms.  

\subsubsection{Divide-and-Conquer}
Side-Channel Attacks go beyond the cryptographic complexity coming from key size, and assuring in classical cryptanalysis a certain security level. Indeed, no matter the size of a cryptographic algorithm inputs, outputs, keys and internal variables, once it is implemented in hardware operations will always be executed over variables of a bounded size. Such a bound depends on the hardware architecture. For example, in an 8-bit architecture an RSA with 1024-bit-sized key, modulo and plaintext will be somehow implemented as multiple operations over 8-bit blocks of observable data. This fact allows an attacker to apply the \emph{divide-and-conquer} strategy: if his goal is to retrieve the full 128-bit AES key or 1024-bit RSA key, he will smartly divide his problem in retrieving small parts of such keys at time, called \emph{subkeys}. 

\subsubsection{Sensitive Variable}
In order to make inference on such subkeys, an attacker acquires side-channels signals, \eg instantaneous power consumption or electromagnetic irradiation, during the execution of the algorithm. Such signals are collected into vectors called \emph{traces} (or \emph{acquisitions}). Such traces will be denoted as observations $\vLeakVec{}$ of a random real vector $\vaLeakVec$, where each coordinate corresponds to a time sample of the acquired signal. The goal of the side-channel analysis is finding the right association between a trace (or a set of traces) and the value assumed by a target \emph{sensitive variable} $\sensRandVar$ during its/their acquisition. A sensitive variable is a quantity handled during the algorithm that tells something about a secret of the implementation. Actually, it would be better to call it \emph{sensitive target}, since it might not be variable. Some typical examples of sensitive variables include: 



\begin{itemize}
\item $\sensRandVar = \keyRandVar$ with $\keyRandVar$ a secret subkey - this is the most direct choice for a sensitive target, nevertheless it is often not variable, since in some cases a device exploits always the same key for a given embedded primitive. When the target is not variable we are performing a \emph{simple attack} (see below);
\item a cryptographic variable that depends over a sufficiently small subkey and a part of a known input variable $\publicParRandVar$: $\sensRandVar = \sensFunction(\keyRandVar,\publicParRandVar)$ - this is the classical choice to perform a so-called \emph{differential} or \emph{advanced} SCA (see below);
\item any function of a cryptographic variable (ex: $\HW(\sensFunction(\keyRandVar,\publicParRandVar))$), where $\HW$ represent the Hamming weight. We will see later in which sense it can be interesting to not target a variable but a non-injective function of a variable as the Hamming weight is;
\item an operation (ex: $\sensRandVar \in \{\mathrm{square}, \mathrm{multiply}\}$)
\item a register (ex: $\sensRandVar$ is the register used to store results of operations in a Montgomery ladder implementation of RSA)
\end{itemize}
In this thesis we will try as much as possible to abstract from the form of the sensitive variable, thinking of any entity $\sensRandVar$ that assumes values in a finite set $\sensVarSet$ and whose value permit an attacker to make inference about a secret of the implemented algorithm.

\subsubsection{Leakage Models}
The underlying hypothesis of a SCA is that some information about internal variables (or parts of internal variables) of the implemented algorithm leak during its execution through some observable \emph{side} channels. Such leakages are collectable in the form of signal traces, observing such channels. Depending on the observed channel (\emph{e.g. power consumption, electromagnetic irradiation, time, \dots}), different properties might influence the form of the leakage, and should be taken into account for the construction of a leakage model.\\
If we allow a Side-Channel attacker to make use of a probing station to directly access the circuit wires and monitor the exact values of some intermediate values, this attacker will observe leakages following the so-called \emph{probing model}. To define this model no further hypothesis are needed, for example no noise is taken into account. As explained in \ref{sec:classification_attacks}, SCAs typically refer to non-invasive attacks, so in Side-Channel literature the probing model has been introduced as a worst-case abstract model, and is mainly considered in order to provide formal security proofs for some kinds of countermeasures. More precisely the $d$-probing model \cite{ishai2003private}, in which an attacker can probe $d$ different wires at a time, provides a good model to exhibit security proofs for $d$-th order masking schemes (cf. \ref{sec:masking}). \\
The most common passive leaking channel considered in literature being the power consumption. For such a physical quantity many efforts have been done to propose adherent leakage models. A detailed modelling for power consumption of CMOS circuits is proposed in the \emph{DPA book} \cite{mangard2008power}. After a description of the physical factors influencing the power consumption (divided into static and dynamic) of single logic cells, the authors propose to assume two different points of view to model and develop simulations of the power consumption: the designer point of view can bring to a quite accurate and detailed model, essentially based over his circuit transistor netlists. On the contrary an attacker would be satisfied by considering some easier modelisation, often based over the \emph{Hamming distance} ($\HD$) or the \emph{Hamming-Weight} ($\HW$) of internal variables. Indeed these two functions well-fit the consumption behaviour of circuits registers and buses, that consume depending on how many bits set to 1 or 0 they store or transport (Hamming weight) or how many of them switch their value for 0 to 1 or vice-versa during computations (Hamming distance). \\
When an attacker has chosen its sensitive target $\sensRandVar$ and deals with concrete acquisitions, he does not need a complete power model, but only  a way to modelise the relative differences between leakages for different values of $\sensRandVar$, in order to distinguish traces related to different values of $\sensRandVar$, or in other terms, closer to the machine learning language, to classify traces depending on their associated value of $\sensRandVar$. A statistical model is then sufficient to him. Thus for an attacker, the wider considered model in Side-Channel community is the one sometimes called \emph{noisy leakage model}. In this model the leakage is a random variable obtained by the sum of a deterministic function of the sensitive variable $\sensRandVar$ and a random noise. In general the noise has a Gaussian distribution of null mean and variance $\sigma^2$:
\begin{equation}
\vaLeak{} = \leakFunction(\sensRandVar) + \noise \mbox{ ,}
\end{equation}
with $\noise \approx \mathcal{N}(0,\sigma^2)$.


\subsubsection{Simple vs Advanced SCAs}
A simple attack corresponds exactly to a classification problem in machine learning language: an attacker observes one single trace, or many traces  An advanced attack is more powerful because exploits synergistically the inferences an attacker can make over many data: observing many different outcomes of the sensitive variable, under known plaintexts, the attacker discard impossible classifications and highlight the correct ones taking advantages of the key hypotheses and the algebraic relation between distinct data. 

\subsubsection{Side-Channel Algebraic Attacks}
Side-Channel Algebraic Attacks are advanced attacks that not only exploit algebraic relations between distinct acquisitions, but also algebraic relations between many sensitive variables within the same acquisition...SASCA ...


\subsubsection{Vertical vs Horizontal SCAs}
Attacks in which sensitive information
is extracted from a single acquisition split into several parts are called \emph{horizontal}. Horizontal attacks may apply when the same sensitive variable is involved in many internal operation during the overall algorithm, or may be the extreme case of  SC Algebraic Attacks in which inferences over many different sensitive variables are done exploiting only one acquisition, than analysing algebraic relations between such sensitive variables. Horizontal attacks differ from the so-called \emph{vertical} attacks where information is obtained from different algorithm
executions. The nice notion of \emph{Rectangle} attack has been introduced in \cite{bauer2013horizontal} to refer to attacks that both exploit vertical and horizontal leakages.

\subsubsection{Profiling vs Non-Profiling SCAs}
As anticipated in Sec.~\ref{sec:this_thesis_objectives}, when an open sample of the attacked device is available to make a prior characterization of the leaking signals of a device, we talk about \emph{profiling} attacks. When this is not the case, we talk about \emph{non-profiling} attacks. \\
A profiling attack is thus divided into two distinct phases. The first one, called \emph{profiling phase} of \emph{characterization} phase exploits some so-called \emph{profiling traces} to build a model of the leakages. Profiling traces are acquisitions taken under known values for the sensitive variable $\sensRandVar$, so are couples $(\vLeakVec{i}, \sensVar_i)_{i=1, \dots , \nbProfilingTraces}$ for which the association trace/sensitive variable is correct. The second phase of a profiling attack is the proper \emph{attack phase}, during which the attacker observes a new set of acquisitions, unknown secret key, and take advantage of the previous characterization to infer over it. \\
As we will see in Chapter~\ref{ChapterIntroML}, in machine learning domain the analogous of profiling attacks context is known under the name of \emph{supervised machine learning}. In supervised machine learning couples $(\vLeakVec{i}, \sensVar_i)_{i=1, \dots , \nbProfilingTraces}$ are available and are called \emph{training examples} (or simply \emph{examples}). The profiling phase is referred to as \emph{training} of \emph{learning} and the attack phase is assimilable to the so-called \emph{test phase}. If no example is available we talk about \emph{unsupervised machine learning}, which corresponds to the non-profiling SCAs branch. 

\subsubsection{Classes}
Throughout this thesis, and each time a profiling attack scenario is supposed,  we will refer to elements of $\sensVarSet$ as \emph{classes}. We will say that acquired traces associated to a same value $\sensVar\in\sensVarSet$ \emph{belong} to the same class $\sensVar$.


\subsubsection{Template Attack}
Introduced in 2004 by Chari \cite{Chari2003}, the so-called \emph{Template Attack} (TA) is the most well-established strategy to run a profiling SCA. The idea of the TA is based over the construction of a so-called \emph{generative model}: in probability, statistic and machine learning \enquote{ ...approaches that explicitly or implicitly model the distribution of inputs as well as outputs are known as generative models, because by sampling from them it is possible to generate synthetic data points in the input space.} \cite{christopher2006pattern}.
In TA the attacker observes the couples $(\vLeakVec{i}, \sensVar_i)_{i=1, \dots , \nbProfilingTraces}$  and exploit them to estimate the class-conditional densities  
\begin{equation}\label{eq:class-conditional}
p_{\vaLeakVec}(\vLeakVec \given \sensRandVar = \sensVar)\mbox{ ,}
\end{equation}
eventually the prior densities $p_{\vaLeakVec}(\vLeakVec)$, $p_{\sensRandVar}(\sensVar)$, and finally the a-posteriori density, by means of the Bayes' theorem:
\begin{equation}\label{eq:a-posteriori}
p_{\sensRandVar}(\sensVar \given \vaLeakVec) = \frac{p_{\vaLeakVec}(\vLeakVec \given \sensRandVar = \sensVar)p_{\sensRandVar}}(\sensVar) {p_{\vaLeakVec}(\vLeakVec)}\mbox{ .}
\end{equation}
In the attack phase the attacker acquires new traces that he only can associate to the public parameter $\publicParRandVar$, obtaining couples  $(\vLeakVec{i}, \publicParVar_i)_{i=1, \dots , \nbAttackTraces}$. Then he makes key hypothesis $\keyVar \in \keyVarSet$ and, making the assumption that each acquisition is an independent observation of $\vaLeakVec$, he associates to each hypothesis a score given by the joint a-posteriori probability that follows, exploiting distributions \eqref{eq:class-conditional}, \eqref{eq:a-posteriori}:

\begin{equation}
d_{\keyVar} = \prod_{i=1}^{\nbAttackTraces}\prob[\sensRandVar = \sensFunction(\publicParVar_i,\keyVar) \given \vaLeakVec = \vLeakVec[i]] \mbox{ .}
\end{equation}

Finally, his best key candidate $\hat{\keyVar}$ is the one maximizing such a joint probability
\begin{equation}\label{eq:max_classifier}
\hat{\keyVar} = \argmax_{\keyVar} d_{\keyVar} \mbox{ .}
\end{equation}

\begin{remark}Since the marginal probability density $p_{\vaLeakVec}(\vLeakVec)$ of \eqref{eq:a-posteriori} does not depend on key hypothesis, it is usually neglected. Moreover, in many cases the $\sensRandVar$ follows a uniform distribution, so its probability mass function $p_{\sensRandVar}(\sensVar)$ appearing in \eqref{eq:a-posteriori}  does not influence the ranking of key hypothesis, then it is often neglected as well. 
\end{remark}

\begin{remark}
In the special case of a simple attack, \ie $\nbAttackTraces = 1$, in which $\sensRandVar = \keyRandVar$, the problem becomes a classical machine learning classification problem (as we will discuss over in Chapter~\ref{ChapterIntroML}: the attacker wants to classify the unique attack trace, \ie assign to it a class label (the key). In such a case, the choice proposed by \eqref{eq:max_classifier} is known as \emph{Bayes (optimal) classifier}.\footnote{The term \emph{optimal} distinguishes it from the so-called \emph{Bayes naive classifier}, which introduces an independence assumption between data vector coordinates. The efficiency of a Bayes naive classifier has been analysed in SCA context in 2017 \cite{picek2017template}.} It is proven to be the optimal choice to reduce de misclassification error.
\end{remark}

In general this approach theoretically exploits all available information and is optimal under an information-theoretical point of view. The crucial point is the estimation of the class-conditional densities \eqref{eq:class-conditional}: the efficiency of the attack strongly depends on the quality of such estimates. 

\paragraph{The Gaussian Hypothesis} A well-established choice to construct class-conditional densities estimations \ref{eq:class-conditional} is the one applied in TA \cite{Chari2003} it consists in making a class-conditional multivariate Gaussian distribution assumption
\begin{equation}\label{eq:gaussian_assumption}
\vaLeakVec\given \sensRandVar =\sensVar \approx \mathcal{N}(\mumumu_\sensVar, \Sigma_\sensVar)\mbox{ ,}
\end{equation} 
and exploits the profiling traces to estimate the  parameters $\mumumu_\sensVar$, \ie the mean vector of the Gaussian distributions, and $ \Sigma_\sensVar$, \ie the covariance matrices. \\

\begin{remark}This assumption is the same that is done for classification problems, bringing to the \emph{Quadratic Discriminant Analysis} technique, which we will describe in Chapter~\ref{ChapterIntroML}. 
\end{remark}

Many options and choices influence the implementation of a TA: the suppression or not of the marginal densities in \eqref{eq:a-posteriori}, the use of the unbiased estimator or the maximum likelihood estimator for the covariance matrices, the addition of an \emph{homoscedasticity} assumption (assume that all class-covariance matrices are equal): This assumption, proposed in 2014 in SCA literature \cite{choudary2014efficient},  allows exploiting all profiling traces to estimate the so-called \emph{pooled} covariance matrix, instead of using traces belonging to each class to estimate each covariance matrix. The pooled estimation gains in accuracy. 

\begin{remark}
This assumption is the same that is done for classification problems, bringing to the \emph{Linear Discriminant Analysis} technique, which we will introduce in Chapter~\ref{ChapterIntroML} and more deeply analyse in Chapter~\ref{ChapterLinear}.  
\end{remark}

Other choices that mainly influences the TA efficiency are those related to the PoI selection, or more generically to the dimensionality reduction issue.

\subsubsection{Points of Interest and Dimensionality Reduction}


\subsubsection{SCA Metrics}



%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
\section{Main Side-Channel Countermeasures}
\subsection{Random Delays and Jitter}
\subsection{Shuffling}
\subsection{Masking}\label{sec:masking}



%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------
\section{Higher-Order Attacks}
\subsection{Higher-Order Moments Analysis and Combining Functions}
\subsection{Profiling Higher-Order Attacks}
\subsubsection{Profiling with Masks Knowledge}
\subsubsection{Profiling without Masks Knowledge}

