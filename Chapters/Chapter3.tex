% Chapter Template

\chapter{Introduction to Machine Learning} % Main chapter title

\label{ChapterIntroML}


\section{Basic Concepts of Machine Learning}
Machine Learning (ML) is a field of computer science that groups a variety of  methods whose aim is giving computers the ability of \emph{learning} without being explicitly programmed. The more cited definition of \emph{learning} has been provided by Mitchell in 1997 \cite{Mitchell1997}: \enquote{ A computer program is said to learn from experience E with respect to some task T and performance measure P, if its performance on T, as measured by P, improves with experience E.} \\
Machine Learning groups a variety of methods essentially coming from applied statistics, and characterized by an increased emphasis on the use of computers to statistically estimate complicated functions. This allows Machine Learning to tackle tasks that would be too difficult to solve with fixed programs written and designed by human being. A Machine Learning algorithm is an algorithm that learns from data, in the sense that is an algorithm able to improve a computer program's performance at some task via an experience.

\subsection{The Task, the Performance and the Experience}
\paragraph*{The task T} is usually described in terms of how the machine learning system should process an \emph{example} (or \emph{data point}). An example is one datum $\vLeakVec\in \mathbb{R}^\traceLength$ , which is in turn a collection of \emph{features} $\vLeakVec[i]$. In SCA context an example is a side-channel trace, which is in turn a collection of time samples, that are its features. Some common ML tasks include these three examples: 
\begin{itemize}
\item \emph{Regression: } the computer is asked to predict a numerical value, given some input. The learning algorithm is thus asked to construct a function $f\colon \mathbb{R}^\traceLength \rightarrow \mathbb{R}$.
\item \emph{Classification: } the computer is asked to specify which class or category an input belongs to, being $\sensVarSet$ the set of the possible classes. The learning algorithm is thus asked to construct a function $f\colon \mathbb{R}^\traceLength \sensVarSet$. We remark that this task is similar to the regression one, except for the form of the output, since in general $\sensVarSet$ is a discrete finite set. As slightly variant solution to the classification task consists in constructing a function $f\colon \mathbb{R}^\traceLength \rightarrow \{0,1\}^{\numClasses}$, once have assigned to each class $\sensVar^j$ a \emph{one-hot encoding}, \ie  a $\numClasses$-dimensional vector,
with all entries equal to $0$ and the $j$-th entry equal to $1$: $\sensVar^j
\rightarrow \vec{\sensVar}^j = (0,\ldots , 0,\underbrace{1}_{j},0,\dots,0)$. A variant of the classification task consists in finding a function $f$ defining a probability distribution over classes.
\item \emph{Verification}: the computer is asked to state whether or not two given inputs are instances of a same class or category, for example state if two hand-written signature have been produced by the same person. The learning algorithm is thus asked to construct a function $f\colon \mathbb{R}^\traceLength \times \mathbb{R}^{traceLength}\rightarrow \{0,1\}$. A variant of such a task consists in finding for a pair of inputs the probability distribution for them being instance or not of a same class. This problem differs from the classification one essentially for the for of the input.
\end{itemize}
The functions constructed by a Machine Learning algorithm, somehow describe and characterize the data form and distribution, thus are often referred to as \emph{models}.

\paragraph*{The performance P} designs a quantitative measure of the abilities of the learning algorithm. Depending on the task T, a specific performance measure P can be considered. For tasks as classification or verification the more common measure is the \emph{accuracy} of the model, \ie the proportion of inputs for which the model produces the correct output. Equivalently, the \emph{error rate} may be used as performance measure P, \ie the proportion of inputs for which the model produces an incorrect output. For the regression task the more common performance measure P is the so-called \emph{Mean Squared Error} (MSE): it is computed by averaging over a finite set of examples, the differences raised to the square between the correct output and the one predicted by the model. \\
One of the crucial challenge of Machine Learning is that we are usually interested in how well a learning algorithm performs in producing a model that fits new, unseen data. For this reason, the performances of a Machine Learning algorithm are usually evaluated over a so-called \emph{test set}, \ie a set of examples that have not been used for the learning (or \emph{training}) phase. 

\paragraph*{The experience E} denotes the typology of access to data and information the algorithm is allowed during learning. In this context we principally distinguish two family of learning algorithms: 
\begin{itemize}
\item the \emph{supervised} learning algorithms experience a dataset of examples, each associated in general to a \emph{target} or \emph{label}. The term supervised reflects the fact the the learning is somehow guided by an instruct that knows the right answer over the learning dataset;
\item the \emph{unsupervised} learning algorithms experience a dataset, without any associated target. They tries to learn useful properties of the structure of the dataset. 
\end{itemize}
In general, the nature of the task is strictly related to the kind of experience the learner is allowed, for example the classification or regression tasks are considered as supervised tasks, while examples of unsupervised tasks include \emph{clustering} and \emph{data representation} or \emph{dimensionality reduction}. The Principal Component Analysis, that will be discussed in Chapter~\ref{ChapterLinear} in the context of SCA, is a dimensionality reduction algorithm that might be seen as an unsupervised algorithm that learns a representation of data. We will see how for SCA context a supervised version of PCA has been proposed as well. 


% examples: Classification, Dimensionality Reduction, Verification
% Example method: Neural Network Classifier, Stacked Auto-Encoder, Siamese Network 

\subsection{Example of Linear Regression}
The regression task is not of high interest for the rest of this thesis, but is the most direct example to keep in mind to understand some basic Machine Learning concepts. Let us introduce a linear regression model so tackle the regression task: we want to construct a linear function $f\colon \mathbb{R}^\traceLength \rightarrow \mathbb{R}$, that takes an input $\vLeakVec$ and outputs $y = \www^\intercal \vLeakVec$, where $\www\in \mathbb{R}^\traceLength$ is a vector of \emph{parameters} that have to be learned by a learning algorithm.\footnote{An affine model may be considered as well by adding a \emph{bias} is added to the model, leading to $y = \www^\intercal \vLeakVec+w_0$. This model is equivalently obtained by adding an additional entry to $\vLeakVec$, always set to $1$ and writing back $y = \www^\intercal \vLeakVec$ with $\www\in \mathbb{R}^{N+1}$. } We want this model well describe some data and we suppose have two available datasets of such data: $\setDataTrain = (\setLeakTrain, \setTargetTrain)$, to let the learning algorithm experience on, and $\setDataTest = (\setLeakTest, \setTargetTest)$ to evaluate the performance of the obtained model over some unseen data. Let us choose the MSE over the test set to evaluate such performances. If we collect the, let say $N$, examples of a dataset as column of a measure matrix $\measuresMatrix\in \mathbb{R}^{\traceLength \times N}$ and the related target into a vector $\yyy\in \mathbb{R}^N$, and let the learned model predict targets $y$ by outputting $\hat{y} = \www\vLeakVec$, then the MSE is given by
\begin{equation}
 \mathrm{MSE_{test}} = \frac{1}{m} \norm{\hat{\yyy}_{\text{test}}-\yyy_{\text{test}}}^2_2 \mbox{ .}
\end{equation}
 The MSE is the performance measure in this example, meaning that we consider the model performs well the most such an MSE is small. So the goal of the learning algorithm is somehow minimize the $\mathrm{MSE_{test}}$. But the learning algorithm only experiences on the $\setDataTrain$ dataset. An intuitive way to act, that can be proven be the maximum likelihood solution to the problem, is to minimize  $\mathrm{MSE_{train}}$ by solving an easy optimization problem. The solution to such a optimization problem can be given in closed form, by means of the pseudo-inverse matrix of $\measuresMatrix_{\text{train}}$:
\begin{equation}
\www = (\measuresMatrix_{\text{train}}\measuresMatrix_{\text{train}}^\intercal)^{-1}\measuresMatrix_{\text{train}}\yyy_{\text{train}}.
\end{equation}


% ispirati dall'esempio sul deep learning book
$\setDataTrain$  $\setDataTest$ $\setDataProfiling=(\setLeak,\setTarget)$
\subsection{Example of Linear Model for Classification}\label{example:LDA}
In this thesis we point out a strict relationship between the profiling SCAs and the classification task in Machine Learning context. For this reason we introduce here a very brief overview of how classically such a task is tackled, by means of linear models. \\
Classify means assigning to an example $\vLeakVec\in\mathbb{R}^\traceLength$ a label $\sensVar\in \sensVarSet$, or equivalently divide the input space $\mathbb{R}^\traceLength$ in \emph{decision regions}, whose boundaries are referred to as \emph{decision boundaries}. Making use of a linear model signifies exploiting some hyperplanes as decision boundaries. Data sets whose classes can be separated exactly by linear decision boundaries are said to be \emph{linearly separable}. Following the discussion kept by Bishop in \cite{christopher2006pattern}, two different approaches to tackle the classification task should be distinguished: the direct research for a discriminant function $f$ that assigns to an example a label, or the prior construction of a probabilistic model. This second approach might in turn be distinguished into two options, depending on whether a generative model, or a discriminative model is constructed. For this example we consider a probabilistic approach, constructing a generative model. This example will allow to introduce some interesting functions, such as the \emph{logistic sigmoid} and the \emph{softmax}, that will play a role in the construction of neural network (see Chapter \ref{ChapterCNN}, and to show how adding some assumptions on the data distributions one can justify, in contexts where the goal of the learning algorithm is making decisions directly, dispensing with any probabilistic interpretation, the exploitation of linear discriminant functions. \\
Construct a generative probabilistic model implies modelling the class-conditional probabilities $\pdf(\vLeakVec\mid \sensVar^j)$ for $j\in [1,\dots,\numClasses]$ as well as the class priors $\pdf(\sensVar^i)$. Let us first consider in a 2-class context, \ie $\numClasses = 2$. Then the posterior probability for the class $\sensVar^1$ is the following:
\begin{equation}\label{eq:post_probs}
\pdf(\sensVar^1\mid \vLeakVec) = \frac{\pdf(\vLeakVec\mid \sensVar^1)\pdf(\sensVar^1)}{\pdf(\vLeakVec\mid \sensVar^1)\pdf(\sensVar^1) + \pdf(\vLeakVec\mid \sensVar^2)\pdf(\sensVar^2)}\mbox{ .}
\end{equation}
To compare the two classes, we can look to their \emph{log-likelihood ratio}:
\begin{equation}\label{eq:log-ratio}
a = \log\left[\frac{\pdf(\sensVar^1\mid \vLeakVec)}{\pdf(\sensVar^2\mid \vLeakVec)}\right] =  \log\left[\frac{\pdf(\vLeakVec\mid \sensVar^1)\pdf(\sensVar^1)}{\pdf(\vLeakVec\mid \sensVar^2)\pdf(\sensVar^2)}\right].
\end{equation}
Then the discriminative criteria can be assigning to $\vLeakVec$ the class $\sensVar^1$ iff $a>0$. The decision boundary is given by the surface defined by $\pdf(\vLeakVec\mid \sensVar^1)\pdf(\sensVar^1) = \pdf(\vLeakVec\mid \sensVar^2)\pdf(\sensVar^2)$.
We remark that we Eq.~\eqref{eq:post_probs} rewrites as
\begin{equation}\label{eq:post_probs_sigmoid}
\pdf(\sensVar^1\mid \vLeakVec) = \frac{1}{1+e^{-a}} = \sigma(a)\mbox{ ,}
\end{equation}
where the function $\sigma$ is the so-called \emph{logistic sigmoid}.\\
In the multi-class case, \ie $\numClasses >2$, the posterior probability for each class $\sensVar^j$ is given by
\begin{equation}\label{eq:post_probs_multi-class}
\pdf(\sensVar^j\mid \vLeakVec) = \frac{\pdf(\vLeakVec\mid \sensVar^j)\pdf(\sensVar^1)}{\sum_k\pdf(\vLeakVec\mid \sensVar^k)\pdf(\sensVar^k )} = \softmax (\aaa)[k]\mbox{ ,}
\end{equation}
where $\aaa$ is a $\numClasses$-dimensional vector, whose entries are given by
\begin{equation}
\aaa[j] = \log\left[ \pdf(\vLeakVec\mid \sensVar^j)\pdf(\sensVar^j) \right] \mbox{ ,}
\end{equation}
and $\softmax$ is the so-called \emph{softmax} function, or \emph{normalized exponential}, that is defined, entry-wise by:
\begin{equation}\label{eq:softmax}
\softmax(\aaa)[k] = \frac{e^{\aaa[k]}}{\sum_{j=1}^{\numClasses}e^{\aaa[j]}}\mbox{ .}
\end{equation}

Let us now introduce two assumptions about class-conditional densities: we will suppose they follow a Gaussian distribution with parameters $\mu_j, \Sigma_j$, and that all class-conditional densities share the same covariance matrix $\Sigma_j=\Sigma$, so that
\begin{equation}
\pdf(\vLeakVec\mid \sensVar^j) = \frac{1}{(2\pi)^{{\traceLength}/2}\lvert \Sigma\rvert^{1/2}}e^{-\frac{1}{2}(\vLeakVec- \mu_j)^\intercal\Sigma^{-1}(\vLeakVec- \mu_j)} \mbox{ .}
\end{equation}
Under this assumptions Eq.~\eqref{eq:log-ratio} rewrites as: 
\begin{equation}\label{eq:LDA-2classes}
a = \log(\frac{\pdf(\sensVar^1)}{\pdf(\sensVar^2)}) - \frac{1}{2}\mu_1^\intercal\Sigma^{-1}\mu_1 + \frac{1}{2}\mu_2^\intercal\Sigma^{-1}\mu_2 - \vLeakVec^\intercal\Sigma^{-1}(\mu_2-\mu_1) = \www^\intercal \vLeakVec + w_0, 
\end{equation}
where we set 
\begin{align*}
\www =& \Sigma^{-1}(\mu_1-\mu_2)\\
w_0 =  & \log\frac{\pdf(\sensVar^1)}{\pdf(\sensVar^2)} - \frac{1}{2}\mu_1^\intercal\Sigma^{-1}\mu_1 + \frac{1}{2}\mu_2^\intercal\Sigma^{-1}\mu_2 . 
\end{align*}
The quadratic terms in $\vLeakVec$ in the exponent of the Gaussian density have cancelled thanks to the common variance assumption, thus we obtain that the decision boundary for the 2-class problem, given by $a=0$ is a $(\traceLength - 1)$-hyperplane of the input space. \footnote{An analogous result can be obtained in the multi-class problem.} This way of choosing linear boundaries is known under the name of \emph{Linear Discriminant Analysis}. Another way to view the same linear classification model is in terms of dimensionality reduction: intuitively, in the 2-class case\footnote{again extensible to the multi-class case} one can see the term $\www^\intercal \vLeakVec$ of \eqref{eq:LDA-2classes} as a projection of the input $\vLeakVec$ onto a one-dimensional subspace of $\mathbb{R}^\traceLength$ orthogonal to the decision boundary mentioned above, then classify the obtained dimensionality-reduced examples by the means of a threshold (that would correspond to $w_0$, in the optimal case). It can be shown that the dimensionality reduction obtained by the Fisher criterion that we will deploy in Chapter~\ref{ChapterLinear}, to which we will refer to LDA dimensionality reduction by a widely accepted abuse, is equivalent to the dimensionality reduction obtained in this example, making the Gaussian assumption over the class-conditional probabilities, equipped of a common covariance matrix assumption.  \\
Relaxing the assumption of a shared covariance matrix and allowing each class-conditional density $\pdf(\vLeakVec\mid \sensVar^j)$ to have its own covariance matrix $\Sigma_j$, then the earlier cancellations will no longer occur, and the discriminant $a$ turns out to be a quadratic function of $\vLeakVec$. This gives rise to the so-called \emph{Quadratic Discriminant Analysis}, that we already mentioned in Chapter~\ref{ChapterIntroductionSCA} for its analogy with Template Attacks.\\

The two assumptions leading to the log-likelihood ratio \eqref{eq:LDA-2classes}, also leads to the following expression for the posterior probability for $\sensVar^1$, directly implied by \eqref{eq:post_probs_sigmoid}: 
\begin{equation}
\pdf(\sensVar^1\mid \vLeakVec) = \sigma(\www^\intercal \vLeakVec + w_0)\mbox{ .}
\end{equation}
Thus such a posterior probability is given by the sigmoid acting to a linear function of $\vLeakVec$. Similarly, for the multi-class case, the posterior probability of class $\sensVar^j$ is given by the $j$-th entry of the softmax transformation of a linear function of $\vLeakVec$. This kind of \emph{generalized linear model} can be thus used in a probabilistic discriminant approach, where the posterior conditional probabilities are directly modelised from data without passing through the estimations of class-conditional densities and priors. Such a discriminative approach is the one that will be adopted in Chapter~\ref{ChapterCNN} when considering neural networks as models.

%the simplest representations of a linear discriminant function is obtained by taking
%\begin{equation}
%f(\vLeakVec) = \www\vLeakVec + w_0 \mbox{ ,}
%\end{equation}
%where $-w_0$ plays the role of a threshold. Here  $\vLeakVec$ is assigned to $\sensVar^1$ if $f(\vLeakVec)>0$, \ie $\www\vLeakVec>-w_0$, otherwise $\vLeakVec$ is assigned to $\sensVar^2$.



% la decision boundary  è un D-1 iperpiano
% introducendo i vettori di target...
% y(x) = wx + w0...oppure in grosso per piu di due classi: la decision boundary è un iperpiano di dimensione (numClasses - 1)
% per imparare i pesi W un'idea è minimizzare il sum error square sti cazzi, un'altra è passare attraverso la riduzione di dimensione e scegliere la riduzione che amplifica la separabilità. 
%Infatti....fisher dà la nozione di ottimalità col quoziente, che porta alla Fisher Discriminant Analysis (o anche LDA, discussa nel Capitolo 6) ... Nel caso numClasses = 2 le due si equivalgono. 
% E interessante discutere brevemente anche di un semplice modello generativo, basato su hp gaussiana, perche tale ipotesi, insieme ad un'altra, porta a costruire anch'essa un modello lineare, giustificando questa scelta in molti contesti...P(x|C)...log del quoziente, funzione sigmoid, logit...softmax...linear piu sigmoid, dove di nuovo la soluzione LDA è la parte lineare (verifica). Se togliamo l'ipotesi sulle covarianze allora resta la parte quadratica e è la QDA (in pratica la parte di classificazione usata nei template attacks)  

\subsection{Training, Validation and Test Sets}
\subsection{Capacity, Underfitting, Overfitting and Regularization}
% parla del linear basis model per regression (è quello che si usa in SCA e aumenta la capacità del modello) oltre alla regressione polinomiale
%\subsection{Data Augmentation}
\subsection{No Free Lunch Theorem}


%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------
\section{Machine Learning Applications in Side-Channel Context}
\subsection{Profiled Attack as a Classification Problem}
\todo{remark that LDA is first of all a linear method for classification and has been introduced in SCA many years ago as preprocessing for Gaussian TA}
\subsubsection{Support Vector Machine}
\subsubsection{Random Forest}
\subsubsection{Neural Networks}

%\begin{table}[]
%\centering
%\caption{Examples of hyper-parameters}
%\label{tab:hyperparameters}
%\begin{tabular}{c|c}
%\multicolumn{1}{c}{\textbf{Training Hyper-Parameters}} & \multicolumn{1}{c}{\textbf{Architecture Hyper-Parameters}}    \\
%\hline
%training set size                             & number of layers                                     \\
%batch size                                    & nature of each layer{\scriptsize  (\eg FC, ACT,$\dots$)} \\
%number of epochs                              & number of units     \rdelim\}{1}{3mm}[{\scriptsize for FC layers}]                 \\
%optimizer algorithm              &  number of filters               \rdelim\}{4}{3mm}[{\scriptsize for CONV layers}]                          \\
%(initial) learning rate              & kernel size                           \\
%                                              & stride                                               \\
%                                                  & padding                                              \\
%                                              & activation function                  \rdelim\}{1}{3mm}[{\scriptsize for ACT layers}]             \\                   
%                                          
%                                              & pooling function        \rdelim\}{3}{3mm}[{\scriptsize for POOL layers}]                                              \\
%                                              & kernel size \\
%                                              & stride                                              
%\end{tabular}
%\end{table}